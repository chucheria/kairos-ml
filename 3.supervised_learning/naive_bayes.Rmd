---
title: "Naive Bayes"
subtitle: "Supervised learning"
author: "Bea Hernández"
date: "`r Sys.Date()`"
output: 
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: inverse, center, middle

# Naive Bayes

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE, eval = FALSE, message = FALSE,
       fig.retina = 3)
```

---
# Naive Bayes Classification

One way to do classification with **probabilities** is through the use of Bayesian statistics. 

We are trying to answer the question: *Based on the features we have, what is the probability that the outcome is class X?* 

A naive Bayes classifier answers this question with a rather bold assumption: all of the predictors we have are **independent** of one another.

---
class: inverse, center, middle

# Bayesian Statistics

---
# Independent variables

Suppose that I ride my bike in `100 races` and I `win 54` of them. The probability of me winning a race, therefore, is just the number of times I’ve won divided by the total number of occurrences:

`P(win) = 54 / 100 = 0.54`

--

Suppose that I want to learn the probability of me `winning a bike race` and the probability of a `wind storm` occurring on Mars. These two things are completely **independent** of each other, given that there being a wind storm on Mars could not possibly affect the result of my bike race, and vice versa. Let’s assume that the probability of a wind storm on Mars is `0.2`. To calculate the probability of both of these independent things happening, we just multiply them:

`P(win and Mars) = P(win) * P(Mars) = 0.54 * 0.2 = 0.108`

---
# Dependent variables

Consider a deck of cards. The probability of me picking any queen is `4/52`. The probability of me picking any ace after picking out a queen, however, is dependent, because we just removed a card from the deck; thus, probability would now be `4/51`. The probability would be defined like this:

`P(Queen and Ace) = P(Queen) × P(Ace | Queen) = (4/52) × (4/51) = 0.006`

--

`P(A and B) = P(A) * P(B | A)`

`P(B) * P(A | B) / P(A) = P(B | A)`

---
# Titanic survival with Naive Bayes

```{r data_titanic, message=F}
library(e1071)
library(tidyverse)
titanic <- as_tibble(Titanic)
head(titanic, n = 3)
```
--

```{r data_ungrouped, message=F}
reps <- rep.int(seq_len(nrow(titanic)), titanic$n)
titanic_df <- titanic[reps, ] %>% select(-n)
head(titanic_df, n = 3)
```

---
# Titanic survival with Naive Bayes

```{r divide_data, message=F, warning = F, fig.align='center', fig.height=5, fig.width=11}
index <- caret::createDataPartition(titanic_df$Survived, p = 0.2, list = F)
train <- titanic_df[index, ]
test <- titanic_df[-index, ]

nb <- naiveBayes(as.factor(Survived) ~., data = train)
nb_p <- predict(nb, newdata = test %>% select(-Survived))
caret::confusionMatrix(as.factor(nb_p), as.factor(test$Survived))
```

---
# Titanic survival with Naive Bayes

```r
A-priori probabilities:
Y
      No      Yes 
0.675737 0.324263 

Conditional probabilities:
     Class
Y            1st        2nd        3rd       Crew
  No  0.08724832 0.09395973 0.34228188 0.47651007
  Yes 0.23776224 0.15384615 0.21678322 0.39160839

     Sex
Y         Female       Male
  No  0.08053691 0.91946309
  Yes 0.41258741 0.58741259

     Age
Y          Adult      Child
  No  0.97651007 0.02348993
  Yes 0.93706294 0.06293706
```

---
# Titanic survival with Naive Bayes

```r
Reference
Prediction   No  Yes
       No  1092  282
       Yes  100  286
                                         
               Accuracy : 0.783          
                 95% CI : (0.7629, 0.802)
    No Information Rate : 0.6773         
    P-Value [Acc > NIR] : < 2.2e-16      
                                         
                  Kappa : 0.458          
 Mcnemar's Test P-Value : < 2.2e-16      
                                         
            Sensitivity : 0.9161         
            Specificity : 0.5035         
         Pos Pred Value : 0.7948         
         Neg Pred Value : 0.7409         
             Prevalence : 0.6773         
         Detection Rate : 0.6205         
   Detection Prevalence : 0.7807         
      Balanced Accuracy : 0.7098         
                                         
       'Positive' Class : No  
```

---
# AUROC: Area under the RoC

Generally speaking, Area Under the RoC (AUROC) statistic is used when you have imbalanced classes.

```{r roc, message=F, eval=F}
library(plotROC)
ggplot(nb_p, 
       aes(m = M, d = factor(obs, levels = c("R", "M")))) + 
    geom_roc(hjust = -0.4, vjust = 1.5) + coord_equal()
```